<?php

return [
    'titre' => 'Aide et compréhension',
    'titre2' => 'Compréhension des types de model de traitement d\'image',
    'titre3' => 'Un réseau de neurones pour la détection d\'objets',
    'detection' => 'Détection',
    'text_detection' => 'La détection IA utilise des algorithmes d\'intelligence artificielle pour identifier et analyser des modèles dans les données. Elle est couramment employée pour la reconnaissance d\'images, la détection de fraudes et l\'analyse de texte. Les systèmes de détection IA apprennent à partir de grandes quantités de données d\'entraînement, permettant une amélioration continue de leur précision. Grâce à des techniques comme le machine learning et le deep learning, ces systèmes peuvent automatiser des tâches complexes. En intégrant des capteurs et des réseaux neuronaux, la détection IA peut fournir des réponses en temps réel et s\'adapter à des environnements changeants.',
    'segmentation' => 'Ségmentation',
    'text_segmentation' => 'La segmentation en intelligence artificielle consiste à diviser une image ou un jeu de données en segments plus petits et homogènes. En vision par ordinateur, cette technique permet d\'identifier et d\'isoler des objets ou des régions spécifiques dans une image. Par exemple, la segmentation d\'images peut séparer les différentes parties d\'un visage ou distinguer les objets sur une route pour une voiture autonome. Les méthodes de segmentation utilisent des algorithmes de machine learning et de deep learning pour améliorer la précision et l\'efficacité. Cette technique est essentielle pour des applications comme l\'analyse médicale, la robotique et la surveillance.',
    'pose' => 'Pose',
    'test_pose' => 'La pose estimation en intelligence artificielle consiste à déterminer la position et l\'orientation d\'objets ou de personnes dans une image ou une vidéo. Cette technique utilise des algorithmes de vision par ordinateur et de deep learning pour repérer des points clés du corps humain ou des caractéristiques d\'un objet. Par exemple, la pose estimation peut identifier les articulations et les mouvements d\'une personne pour des applications de réalité augmentée ou de suivi sportif. En analysant les relations entre ces points clés, le système peut comprendre et imiter les mouvements dans un espace tridimensionnel. Cette technologie est utilisée dans les domaines de la santé, de la sécurité et du divertissement pour améliorer l\'interaction homme-machine.',
    'obb' => 'OBB',
    'text_obb' => 'L\'orientation et la détection des boîtes englobantes orientées (Oriented Bounding Boxes, OBB) en intelligence artificielle impliquent la création de boîtes qui encapsulent des objets avec une orientation précise. Contrairement aux boîtes englobantes classiques, qui sont alignées avec les axes de l\'image, les OBB peuvent s\'incliner pour mieux épouser la forme des objets. Cette technique est particulièrement utile dans des applications telles que la reconnaissance de texte en milieu complexe, la détection d\'objets dans des images aériennes ou satellitaires, et l\'analyse de scènes urbaines. Les algorithmes de deep learning sont souvent utilisés pour apprendre à détecter et dessiner ces OBB, permettant une détection plus précise et adaptée à la réalité des formes et orientations des objets.',
    'introduction' => 'Nous, les humains, avons un système visuel rapide et précis, ce qui nous permet d\'effectuer des tâches complexes comme la conduite avec peu de réflexion consciente. En effet, nous savons inconsciemment quels sont les objets que nous voyons, où ils se trouvent et comment ils interagissent.',
    'algorithms_overview' => 'Au cours des dernières années, des algorithmes rapides et précis se sont mis en place pour la reconnaissance d\'objets dans une image. Plus de détails sur ces différents algorithmes dans la page wikipédia : https://fr.wikipedia.org/wiki/Reconnaissance_de_formes. La reconnaissance d\'objets est un terme général pour décrire un ensemble de tâches de vision par ordinateur qui impliquent l\'identification d\'objets dans des photographies numériques. Il existe différents types de reconnaissance d’objets :',
    'image_classification' => '- La classification d\'images consiste à prédire la classe d\'un objet dans une image.',
    'image_classification_input' => '- Entrée : une image avec un seul objet.',
    'image_classification_output' => '- Sortie : une étiquette de classe.',
    'object_localization' => '- La localisation d\'objets consiste à identifier l\'emplacement d\'un ou plusieurs objets dans une image et à dessiner un cadre de délimitation autour de leur étendue.',
    'object_localization_input' => '- Entrée : une image avec un ou plusieurs objets.',
    'object_localization_output' => '- Sortie : un ou plusieurs cadres de délimitation.',
    'object_detection' => '- La détection d\'objets combine ces deux tâches et dessine un cadre de délimitation autour de chaque objet dans l\'image et leur attribue une classe.',
    'object_detection_input' => '- Entrée : une image avec un ou plusieurs objets.',
    'object_detection_output' => '- Sortie : un ou plusieurs cadres de délimitation et une étiquette de classe pour chaque cadre de délimitation.',
    'article_intro' => 'Nous allons tout d’abord survoler l’approche globale d’un des réseaux de neurones qui permet de faire de la détection d’objets sur des images, à savoir le réseau de neurones You Only Look Once plus communément appelé YOLO puis, nous allons entrer plus en profondeur sur son comportement ainsi que son architecture pour au final, voir à travers un cas particulier la détection d’objets se trouvant sur la route tels que les feux tricolores, les panneaux de direction, les piétons, etc en installant une caméra dans une voiture et en récupérant les images prises par cette dernière.',
    'general_approach' => 'Approche générale',
    'yolo_family' => 'Il s\'agit d\'une famille populaire de modèles de reconnaissance d\'objets est appelée YOLO ou « You Only Look Once », décrite pour la première fois par Joseph Redmon et al. dans l\'article de 2015 intitulé “You Only Look Once: Unified, Real-Time Object Detection.” (https://arxiv.org/abs/1506.02640). Ce modèle réalise une détection d’objets en temps réel : il traite les images à 30 images par seconde (IPS).',
    'yolo_functioning' => 'Le fonctionnement de YOLO',
    'yolo_approach' => 'L\'approche implique un réseau de neurones qui met bout-à-bout une multitude de neurones et qui prend une photo en entrée et prédit directement les cadres de délimitation, plus communément appelés "bounding box", et les étiquettes de classe pour chaque cadre de délimitation.',
    'yolo_grid' => 'Le modèle fonctionne en divisant d\'abord l\'image d\'entrée en une grille de cellules, où chaque cellule est responsable de la prédiction d\'un cadre de délimitation. Une prédiction de classe est également basée sur chaque cellule.',
    'example_grid' => 'Par exemple, une image peut être divisée en une grille 7 × 7 et imaginons que chaque cellule de la grille peut prédire 2 cadres de délimitation, ce qui donne 98 prédictions de cadres de délimitation proposées. La carte des probabilités de classe et les cadres de délimitation avec confiance sont ensuite combinés en un ensemble final de cadres de délimitation et d\'étiquettes de classe. L\'image ci-dessous résume les deux sorties du modèle.',
    'yolo_prediction_example' => 'Exemple de la prédiction faite par YOLO',
    'yolo_deeper_look' => 'Plus en profondeur',
    'yolo_grid_analysis' => 'Dans un premier temps, comme dit dans l’introduction, YOLO applique une grille sur l’image qui ne sert pas à segmenter l’image, pour analyser séparément chaque portion, comme le ferait un R-CNN. En effet, Le R-CNN est une architecture de détection d\'objets qui commence par extraire des régions intéressantes de l’image, puis utilise ces régions comme données d’entrée pour un CNN. Cette séparation en régions permet de détecter plusieurs objets de plusieurs classes différentes dans une même image. Pour plus de détails sur le fonctionnement du R-CNN, se référer à la page towards data science : https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e.',
    'grid_application' => 'Application de la grille',
    'yolo_anchor_boxes' => 'Au contraire, avec YOLO, les carrés de la grille sont utilisés pour générer un certain nombre d’anchor boxes. Ces anchor boxes sont un des concepts les plus difficiles à saisir lors de l\'apprentissage des réseaux de neurones convolutifs pour la détection d\'objets. C\'est également l\'un des paramètres les plus importants que vous pouvez régler pour améliorer les performances de votre ensemble de données. En fait, si les anchor boxes ne sont pas réglés correctement, votre réseau de neurones ne saura jamais que certains objets petits, grands ou irréguliers existent et n\'aura jamais la chance de les détecter.',
    'anchor_box_definition' => 'Une anchor box est une boîte englobante (un rectangle sur l’image) définie d\'une certaine hauteur et largeur (voir l’image ci-dessous en bleu). En effet, L\'utilisation d’anchor boxes permet à un réseau de détecter plusieurs objets, des objets d\'échelles différentes et des objets qui se chevauchent.',
    'anchor_box_generation' => 'Génération des anchor boxes',
    'low_prob_anchor_boxes' => 'La première étape, tout naturellement, est de se débarrasser de toutes les anchor boxes qui ont une faible probabilité qu\'un objet soit détecté. Cela peut être fait en construisant un masque booléen (tf.boolean_mask dans tensorflow), et en ne gardant que les cases qui ont une probabilité supérieure à un certain seuil. Cette étape élimine les détections anormales \'objets.',
    'anchor_box_filtering' => 'Cependant, même après un tel filtrage, on se retrouve avec de nombreuses anchor boxes pour chaque objet détecté. Mais nous n\'avons besoin que d\'une seule boîte. Cette-ci est calculée à l\'aide de la suppression non max https://leonardoaraujosantos.gitbook.io/artificial-inteligence/machine_learning/deep_learning/single-shot-detectors/yolo#:~:text=Maxima%20Suppression%20(nms)-,During%20prediction,-time%20(after%20training',
    'nms_process' => 'La suppression non max fonctionne comme suit :',
    'nms_step1' => '1. On supprime les anchor boxes ayant une probabilité inférieure à un certain seuil, 0.6 par exemple;',
    'nms_step2' => '2. On sélectionne l’anchor box avec la probabilité de détection la plus élevée;',
    'nms_step3' => '3. On supprime les anchor boxes qui intersectent l’anchor box sélectionnée en 2) ayant un IoU supérieur à un certain seuil, 0.5 généralement. En clair, on supprime les anchor boxes trop proches les unes des autres dans cette étape car elles labelisent le même objet;',
    'nms_step4' => '4. On répète les étapes 2 et 3 jusqu’à ce qu’il ne reste plus d’anchor boxes à traiter.',
    'iou_concept' => 'Dans l’étape 3, la suppression non max utilise un concept appelé « Intersection over Union » ou IoU. Il prend en entrée deux anchor boxes et, comme son nom l\'indique, il calcule le rapport de l\'intersection et de l\'union des deux.',
    'iou_example' => 'Pour mieux comprendre comment est calculé cet indice, zoomons sur l’image et concentrons-nous sur les anchor boxes vert et jaune :',
    'iou_calculation' => 'Calcul de l’IoU',
    'iou_formula' => 'L’IoU est calculé en divisant l’intersection des 2 anchor boxes par leur union. En d’autres termes, la formule revient à diviser la partie rouge par la partie bleue.',
    'iou_interpretation' => 'En général, on considère que :',
    'iou_threshold' => '- Si IoU > 0.5 entre 2 anchor boxes, cela signifie qu’elles labellisent le même objet.',
    'final_image' => 'Après l’exécution de l’algorithme, l’image finale est la suivante. Là, nous pouvons remarquer que l’IoU permet de réduire la sélection d’anchor boxes en passant d’une vingtaine d’anchor boxes à seulement 2 qui caractérisent ici 2 objets, à savoir, la voiture et la personne :',
    'yolo_final_detection' => 'Détection finale d’objets grâce à YOLO',
    'yolo_practice_image' => 'Sur cet exemple, cela paraît simple : la grille est petite, il y a peu d’anchor boxes... Mais en pratique, cela ressemble plutôt à l’image ci-dessous. Dans cette suite d\'images, nous remarquons que l’image a été découpée en plusieurs carrés (image 1) qui permettent de générer plusieurs anchor boxes (image 2). L’IoU est ensuite calculé pour regrouper les anchor boxes qui détectent le même objet (nous pouvons le voir à travers les groupes de couleurs sur l’image3). Puis finalement, grâce à l’algorithme de Non-Max Suppression, nous passons de milliers d’anchor boxes à seulement 2 pour détecter un chien et un vélo (image4) :',
    'yolo_architecture' => 'Architecture de YOLO',
    'yolo_architecture_details' => 'Après avoir étudié le comportement général du réseau de neurones YOLO, nous allons maintenant nous intéresser à son architecture. YOLO se compose d\'un total de 24 couches convolutives suivies de 2 couches entièrement connectées. Les couches sont séparées par leur fonctionnalité de la manière suivante :',
    'yolo_layers' => '- Les 20 premières couches convolutives sont pré-entraînées sur l\'ensemble de données de classification ImageNet 1000-class.',
    'yolo_layer_composition' => '- Les couches comprennent des couches de réduction 1x1 et des couches convolutives 3x3.',
    'additional_layers' => '- Les 4 dernières couches convolutives suivies de 2 couches entièrement connectées sont ajoutées pour entraîner le réseau à la détection d\'objets avec notre base de données.',
    'final_layer' => '- La couche finale prédit les probabilités de classe et les cadres de délimitation.',
    'transfer_learning' => '→  C\'est une technique classique d\'entraînement par transfert (transfer learning). On prend un modèle déjà entraîné sur une tâche assez générique et on le spécialise sur une tâche d\'intérêt en re entraînant uniquement les dernières couches du réseau avec des données spécifiques à cette tâche. (Pour en savoir plus : https://en.wikipedia.org/wiki/Transfer_learning)',
    'yolo_input_output' => '→ L\'entrée est une image de 448 x 448 et la sortie est la prédiction de classe de l\'objet enfermé dans la boîte englobante.',
    'yolo_architecture_image' => 'L’architecture de YOLO',
    'practice_autonomous_cars' => 'Et dans la pratique, ça donne quoi ?',
    'case_autonomous_cars' => 'Cas particulier : voitures autonomes',
    'autonomous_car_intro' => 'Il est temps maintenant de mettre en pratique les notions abordées dans les parties précédentes à travers un cas particulier, à savoir le cas des voitures autonomes. En effet, pour qu’une voiture puisse circuler sans conducteur, plusieurs points doivent être mis en place tels que l’accélération, le freinage, la direction de la voiture, etc. Dans notre cas, nous allons nous focaliser uniquement sur la détection de certains objets sur la route à savoir : ',
    'camera_integration' => 'Notre but est d’intégrer une caméra dans une voiture afin que cette caméra détecte ces objets se trouvant sur la route.',
    'database_creation' => 'Création de la base de données',
    'database_creation_details' => 'Pour atteindre ce but, nous commençons par installer une caméra dans une voiture en déplacement en agglomération. Nous filmons la route du côté passager de la voiture un jour d’été (dans ce cas pratique, les différentes conditions météorologiques n’ont pas été prises en compte) pendant 2 minutes 30. Puis, au moyen d’un script, nous récupérons une image pour chaque seconde de vidéo, soit au total 150 images. Ci-dessous une image parmi les 150 de notre base de données :',
    'database_image_example' => 'Exemple d’une image de la base de données',
    'data_labeling' => 'Labellisation',
    'labeling_process' => 'Une fois cette base de données créée, nous labellisons ces images grâce à un projet open source nommé “YOLO Annotation Tool”, particulièrement adapté pour une utilisation des données sur YOLO (https://github.com/ManzarIMalik/YOLO-Annotation-Tool).',
    'labeling_details' => 'Cette labellisation consiste, pour chaque image du jeu de données, à tracer des rectangles autour des objets que l’on souhaite reconnaître, en précisant pour chaque rectangle la classe de l’objet qu’il désigne (feu rouge, voiture, piétons...). Comme on peut le voir dans l’image ci-dessous, nous avons tracé les 3 rectangles roses en leur assignant la classe de voiture puis les 2 rectangles bleus représentant les feux rouges.',
    'labeling_example' => 'YOLO Annotation Tool : Exemple de labellisation',
    'labeling_output' => 'Cela va produire pour chaque image un fichier texte contenant les informations de classe et de position sur l’image de chaque objet labellisé. Puis, nous utilisons ce fichier texte pour ré entraîner les 4 dernières couches du réseau à la détection d\'objets avec notre base de données.',
    'algorithm_execution' => 'Exécution de l’algorithme',
    'algorithm_training' => 'Pendant l\'entraînement des dernières couches du réseau de neurones YOLO avec notre base de données, voici ce que l’on voit :',
    'training_output' => 'Sorties pendant l\'entraînement de YOLO',
    'training_details' => '5981 : nombre d’itérations,',
    'avg_loss' => 'Avg loss : l’erreur moyenne → On s’attend à ce qu’elle soit la plus petite possible et on se sert de cela pour décider quand arrêter l’entraînement ;',
    'learning_rate' => 'Rate : taux d’apprentissage utilisé pour mettre à jour les poids ;',
    'image_count' => 'Image : le nombre d’images total pour l’entraînement ;',
    'loading_time' => 'Loaded : le temps pour changer les images ;',
    'avg_iou' => 'Region Avg IoU : l’Intersection over Union ;',
    'class_prob' => 'Class : la moyenne des probabilités des vrais positifs. Si on prend l’exemple de la troisième ligne 94,00 % des objets détectés dans cette sous-division appartiennent à leurs classes correctes ;',
    'obj_prob' => 'Obj : la probabilité que la boîte contienne un objet ; Dans cet exemple, l’entraînement est à 57.96 % confiant que les boîtes englobantes contiennent un objet;',
    'no_obj_prob' => 'No Obj : même chose que précédemment mais pour les endroits où il n’y a pas d’objet, donc on s’attend à des valeurs basses ;',
    'avg_recall' => 'Avg Recall : parmi les objets à détecter, le nombre d’objets qu’il a réellement détectés;',
    'object_count' => 'Count : le nombre total d’objets détectés dans cette subdivision.',
    'training_result' => 'Une fois le réseau entraîné, voici le résultat sur une image donnée :',
    'result_image' => 'Résultat après entrainement de YOLO sur une image donnée',
    'result_observation' => 'On remarque que le réseau a bien détecté les trois panneaux de direction et les deux voitures.',
    'conclusion' => 'Conclusion',
    'yolo_summary' => 'YOLO est un réseau de neurones qui traite toute l’image d’un seul coup d’où le nom “You Only Look Once”, ce qui va lui permettre de faire de la détection en temps réel sur des vidéos. Rappelons qu\'il traite les images à 30 images par seconde (IPS). Cette détection en temps réel est un véritable atout notamment pour des cas d\’usage bien précis comme l\’exemple vu de la voiture autonome ou encore de la réalité augmentée.',
    'yolo_application' => 'En effet, après avoir installé une caméra dans une voiture en déplacement et après avoir récupéré les images prise par la caméra, YOLO nous a permis  de faire de la détection d’objets sur la route tels que les feux tricolores, les panneaux de direction, les piétons ainsi que les voitures.',
    'alternative_models' => 'Toutefois, YOLO n’est pas le seul modèle existant capable de faire de la détection. Il en existe plusieurs autres tels que R-CNN, fast R-CNN, faster R-CNN...',
    'yolo_speed_advantage' => 'Mais ce qui rend YOLO différent de ces derniers est sa vitesse d’exécution. En effet, les différents modèles du type "R-CNN" vont définir, pour chaque image en entrée (selon des méthodes spécifiques aux différentes versions de R-CNN), un ensemble de régions susceptibles de contenir un objet recherché. Le réseau de neurones va analyser chacune de ces régions séparément et déterminer si elles contiennent un objet ou non, et si oui, la classe correspondante. Pour chaque image passée en entrée, le réseau va donc devoir définir et analyser une multitude de régions, ce qui prend du temps.',
];
